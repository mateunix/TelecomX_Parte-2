# -*- coding: utf-8 -*-
"""TelecomX_BR.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZPf4dbkq4xKCYTo-JAQ2w5bKtT5qn-pQ

#üìå Extrac√£o
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# --- 1. CONFIGURA√á√ÉO INICIAL ---
# Ajustes para melhor visualiza√ß√£o no terminal
pd.set_option('display.max_columns', None)
pd.set_option('display.width', 1000)
pd.set_option('display.float_format', '{:.2f}'.format)

# Estilo dos gr√°ficos
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (12, 8)

print("üöÄ INICIANDO PIPELINE DE DADOS COMPLETO (TELECOM X)...\n")

# =============================================================================
# ETAPA 1: EXTRA√á√ÉO (EXTRACTION)
# =============================================================================
url_api = "https://raw.githubusercontent.com/ingridcristh/challenge2-data-science/main/TelecomX_Data.json"
print(f"üîÑ [1/7] Baixando dados de: {url_api}...")

try:
    df_raw = pd.read_json(url_api)
    print("   ‚úÖ Download conclu√≠do.")
except Exception as e:
    print(f"   ‚ùå Erro cr√≠tico no download: {e}")
    exit()

"""#üîß Transforma√ß√£o"""

print("\nüõ†Ô∏è  [2/7] Normalizando dados aninhados (JSON)...")

# Expandindo os dicion√°rios internos
df_customer = pd.json_normalize(df_raw['customer'].tolist())
df_phone    = pd.json_normalize(df_raw['phone'].tolist())
df_internet = pd.json_normalize(df_raw['internet'].tolist())
df_account  = pd.json_normalize(df_raw['account'].tolist())

# Concatenando
df_final = pd.concat([df_raw[['customerID', 'Churn']], df_customer, df_phone, df_internet, df_account], axis=1)
print(f"   üìä Dimens√µes ap√≥s normaliza√ß√£o: {df_final.shape}")

# =============================================================================
# ETAPA 3: LIMPEZA DE DADOS (CLEANING)
# =============================================================================
print("\nüßπ [3/7] Limpando inconsist√™ncias...")

# 3.1. Remover Churn vazio
df_final = df_final[df_final['Churn'] != '']

# 3.2. Converter 'Charges.Total' para n√∫mero (tratando espa√ßos como NaN)
df_final['Charges.Total'] = pd.to_numeric(df_final['Charges.Total'], errors='coerce')
df_final['Charges.Total'] = df_final['Charges.Total'].fillna(0)

# 3.3. Remover espa√ßos em branco de todas as colunas de texto
colunas_texto = df_final.select_dtypes(include=['object']).columns
for col in colunas_texto:
    df_final[col] = df_final[col].str.strip()

print("   ‚úÖ Limpeza conclu√≠da.")

# =============================================================================
# ETAPA 4: ENGENHARIA DE ATRIBUTOS - PARTE 1
# =============================================================================
print("\n‚öóÔ∏è  [4/7] Criando vari√°veis derivadas...")

# Criando Custo Di√°rio
df_final['Contas_Diarias'] = df_final['Charges.Monthly'] / 30

# =============================================================================
# ETAPA 5: PADRONIZA√á√ÉO E TRADU√á√ÉO
# =============================================================================
print("\nüåç [5/7] Traduzindo e Padronizando...")

# 5.1. Renomeando Colunas
mapa_colunas = {
    'customerID': 'ID_Cliente',
    'Churn': 'Evasao',
    'gender': 'Genero',
    'SeniorCitizen': 'Idoso',
    'Partner': 'Parceiro',
    'Dependents': 'Dependentes',
    'tenure': 'Meses_Contrato',
    'PhoneService': 'Servico_Telefonico',
    'MultipleLines': 'Multiplas_Linhas',
    'InternetService': 'Servico_Internet',
    'OnlineSecurity': 'Seguranca_Online',
    'OnlineBackup': 'Backup_Online',
    'DeviceProtection': 'Protecao_Dispositivo',
    'TechSupport': 'Suporte_Tecnico',
    'StreamingTV': 'Streaming_TV',
    'StreamingMovies': 'Streaming_Filmes',
    'Contract': 'Contrato',
    'PaperlessBilling': 'Fatura_Digital',
    'PaymentMethod': 'Metodo_Pagamento',
    'Charges.Monthly': 'Cobranca_Mensal',
    'Charges.Total': 'Cobranca_Total',
    'Contas_Diarias': 'Custo_Diario'
}
df_final.rename(columns=mapa_colunas, inplace=True)

# 5.2. Traduzindo Valores
df_final['Genero'] = df_final['Genero'].map({'Female': 'Feminino', 'Male': 'Masculino'})
df_final['Contrato'] = df_final['Contrato'].replace({
    'Month-to-month': 'Mensal', 'One year': '1 Ano', 'Two year': '2 Anos'
})
df_final['Metodo_Pagamento'] = df_final['Metodo_Pagamento'].replace({
    'Electronic check': 'Cheque Eletr√¥nico', 'Mailed check': 'Cheque Enviado',
    'Bank transfer (automatic)': 'Transfer√™ncia Banc√°ria', 'Credit card (automatic)': 'Cart√£o de Cr√©dito'
})
df_final['Servico_Internet'] = df_final['Servico_Internet'].replace('Fiber optic', 'Fibra √ìptica')
df_final['Idoso'] = df_final['Idoso'].map({0: 0, 1: 1}) # Mantendo 0/1 mas garantindo int

# 5.3. Codifica√ß√£o Bin√°ria (Yes/No -> 1/0)
colunas_binarias = ['Evasao', 'Parceiro', 'Dependentes', 'Servico_Telefonico', 'Fatura_Digital',
                    'Seguranca_Online', 'Backup_Online', 'Protecao_Dispositivo',
                    'Suporte_Tecnico', 'Streaming_TV', 'Streaming_Filmes']

mapa_binario = {'Yes': 1, 'No': 0, 'No internet service': 0, 'No phone service': 0}

for col in colunas_binarias:
    df_final[col] = df_final[col].replace(mapa_binario).astype(int)

# =============================================================================
# ETAPA 6: ENGENHARIA DE ATRIBUTOS - PARTE 2 (P√≥s-Codifica√ß√£o)
# =============================================================================
# Agora que os servi√ßos s√£o 0 e 1, podemos som√°-los facilmente
cols_servicos = [
    'Seguranca_Online', 'Backup_Online', 'Protecao_Dispositivo',
    'Suporte_Tecnico', 'Streaming_TV', 'Streaming_Filmes'
]
df_final['Qtd_Servicos'] = df_final[cols_servicos].sum(axis=1)
print("   ‚úÖ Vari√°veis criadas e traduzidas.")

"""#üìä Carga e an√°lise"""

print("\nüìä [7/7] Gerando Gr√°ficos e Relat√≥rios (Visualiza√ß√£o Amig√°vel)...")

# --- A. Distribui√ß√£o de Churn (Pizza e Barras) ---
fig, ax = plt.subplots(1, 2, figsize=(14, 6))

# Gr√°fico 1: Barras
sns.countplot(data=df_final, x='Evasao', palette=['#4c72b0', '#c44e52'], ax=ax[0])
ax[0].set_title('Quantidade Absoluta de Evas√£o')
ax[0].set_xlabel('Cancelou o Servi√ßo?')
ax[0].set_xticklabels(['N√£o', 'Sim']) # <--- AQUI A MUDAN√áA

# Gr√°fico 2: Pizza
df_final['Evasao'].value_counts().plot.pie(
    autopct='%1.1f%%',
    colors=['#4c72b0', '#c44e52'],
    labels=['N√£o', 'Sim'], # <--- AQUI A MUDAN√áA
    ax=ax[1],
    explode=(0, 0.1)
)
ax[1].set_title('Taxa de Evas√£o (Churn Rate)')
ax[1].set_ylabel('')

plt.tight_layout()
plt.savefig('1_distribuicao_evasao.png')
print("   üì∏ Salvo: 1_distribuicao_evasao.png")


# --- B. An√°lise Categ√≥rica (Grid 2x2) ---
cols_cat = ['Genero', 'Servico_Internet', 'Contrato', 'Metodo_Pagamento']
fig, axes = plt.subplots(2, 2, figsize=(18, 12))
plt.subplots_adjust(hspace=0.4, wspace=0.3)

for i, col in enumerate(cols_cat):
    ax_atual = axes[i//2, i%2]
    sns.countplot(data=df_final, x=col, hue='Evasao', palette=['#4c72b0', '#c44e52'], ax=ax_atual)

    ax_atual.set_title(f'Evas√£o por {col}')
    ax_atual.set_xlabel('')
    ax_atual.tick_params(axis='x', rotation=10)

    # Ajustando a legenda para Sim/N√£o
    ax_atual.legend(title='Cancelou?', labels=['N√£o', 'Sim']) # <--- AQUI A MUDAN√áA

plt.tight_layout()
plt.savefig('2_analise_categorias.png')
print("   üì∏ Salvo: 2_analise_categorias.png")


# --- C. An√°lise Num√©rica (Boxplots) ---
fig, axes = plt.subplots(1, 3, figsize=(18, 6))
vars_num = ['Meses_Contrato', 'Cobranca_Mensal', 'Cobranca_Total']
titulos = ['Tenure (Tempo)', 'Mensalidade', 'LTV (Total)']

for i, col in enumerate(vars_num):
    sns.boxplot(data=df_final, x='Evasao', y=col, palette=['#4c72b0', '#c44e52'], ax=axes[i])
    axes[i].set_title(titulos[i])
    axes[i].set_xlabel('Cancelou?')
    axes[i].set_xticklabels(['N√£o', 'Sim']) # <--- AQUI A MUDAN√áA

plt.tight_layout()
plt.savefig('3_analise_numerica_boxplots.png')
print("   üì∏ Salvo: 3_analise_numerica_boxplots.png")


# --- D. Ranking de Correla√ß√£o (Este continua num√©rico pois √© matem√°tico) ---
plt.figure(figsize=(8, 10))
# Seleciona apenas num√©ricos
cols_corr = df_final.select_dtypes(include=['number']).columns
corr = df_final[cols_corr].corr()

corr['Evasao'].drop('Evasao').sort_values(ascending=False).plot(kind='barh', color='#c44e52')
plt.title('Fatores que mais impactam a Evas√£o (+1 = Sim, -1 = N√£o)')
plt.grid(axis='x', linestyle='--', alpha=0.5)
plt.tight_layout()
plt.savefig('5_ranking_fatores.png')
print("   üì∏ Salvo: 5_ranking_fatores.png")

"""#üìÑRelatorio Final



"""

print("\n" + "="*50)
print("‚úÖ RELAT√ìRIO FINAL GERADO COM SUCESSO")
print("="*50)
print(f"üë• Total de Clientes Analisados: {df_final.shape[0]}")
print(f"üìâ Taxa Global de Evas√£o: {(df_final['Evasao'].mean() * 100):.2f}%")
print(f"üí∞ Ticket M√©dio Mensal: R$ {df_final['Cobranca_Mensal'].mean():.2f}")
print("-" * 50)
print("Arquivos de imagem gerados na pasta do projeto:")
print("1. 1_distribuicao_evasao.png")
print("2. 2_analise_categorias.png")
print("3. 3_analise_numerica_boxplots.png")
print("4. 4_matriz_correlacao.png")
print("5. 5_ranking_fatores.png")
print("="*50)

"""#üöÄETAPA 8 ‚Äî Prepara√ß√£o para Modelagem"""

# =============================================================================
# ETAPA 8: PREPARA√á√ÉO PARA MODELAGEM
# =============================================================================
print("\nü§ñ [8/10] Preparando dados para Machine Learning...")

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Vari√°vel alvo
y = df_final['Evasao']

# Removendo ID e target das features
X = df_final.drop(columns=['ID_Cliente', 'Evasao'])

# One-Hot Encoding para vari√°veis categ√≥ricas restantes
X = pd.get_dummies(X, drop_first=True)

# Separando treino e teste
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.25, random_state=42, stratify=y
)

# Padroniza√ß√£o (importante para regress√£o log√≠stica)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print("   ‚úÖ Dados prontos para modelagem.")

"""#üß† ETAPA 9 ‚Äî Treinamento de Modelos"""

# =============================================================================
# ETAPA 9: TREINAMENTO DOS MODELOS
# =============================================================================
print("\nüß† [9/10] Treinando modelos...")

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import classification_report, roc_auc_score

# 1Ô∏è‚É£ Logistic Regression
log_model = LogisticRegression(max_iter=1000)
log_model.fit(X_train_scaled, y_train)

# 2Ô∏è‚É£ Random Forest
rf_model = RandomForestClassifier(n_estimators=300, random_state=42)
rf_model.fit(X_train, y_train)

# 3Ô∏è‚É£ Gradient Boosting
gb_model = GradientBoostingClassifier()
gb_model.fit(X_train, y_train)

print("   ‚úÖ Modelos treinados.")

"""#üìä ETAPA 10 ‚Äî Avalia√ß√£o de Desempenho"""

# =============================================================================
# ETAPA 10: AVALIA√á√ÉO
# =============================================================================
print("\nüìà [10/10] Avaliando modelos...")

models = {
    "Logistic Regression": (log_model, X_test_scaled),
    "Random Forest": (rf_model, X_test),
    "Gradient Boosting": (gb_model, X_test)
}

for name, (model, X_eval) in models.items():
    y_pred = model.predict(X_eval)
    y_proba = model.predict_proba(X_eval)[:,1]

    print(f"\nüîé Modelo: {name}")
    print(classification_report(y_test, y_pred))
    print("ROC-AUC:", round(roc_auc_score(y_test, y_proba), 4))

"""#üìå Import√¢ncia das Vari√°veis


"""

# Import√¢ncia - Random Forest
importances = pd.Series(rf_model.feature_importances_, index=X.columns)
importances = importances.sort_values(ascending=False)

plt.figure(figsize=(8,10))
importances.head(15).plot(kind='barh')
plt.title("Top 15 Vari√°veis Mais Importantes (Random Forest)")
plt.gca().invert_yaxis()
plt.tight_layout()
plt.savefig("6_importancia_variaveis.png")

"""O Random Forest calcula a import√¢ncia das vari√°veis com base na redu√ß√£o da impureza (Gini) gerada por cada atributo ao longo das √°rvores.

**Principais insights:**
- O tempo de contrato √© a vari√°vel mais importante para prever a evas√£o.
- O valor da cobran√ßa mensal e o tipo de contrato tamb√©m possuem grande impacto.
- A combina√ß√£o de custo e fideliza√ß√£o √© determinante para o churn.

"""

# Coeficientes da Regress√£o Log√≠stica
coef_log = pd.Series(
    log_model.coef_[0],
    index=X.columns
).sort_values()

plt.figure(figsize=(8,10))
coef_log.tail(10).plot(kind='barh', color='red')
coef_log.head(10).plot(kind='barh', color='blue')
plt.title("Coeficientes da Regress√£o Log√≠stica")
plt.tight_layout()

"""Na Regress√£o Log√≠stica, os coeficientes indicam a contribui√ß√£o de cada vari√°vel para a probabilidade de evas√£o.

Coeficientes positivos aumentam a chance de evas√£o, enquanto coeficientes negativos reduzem essa probabilidade.
A magnitude do coeficiente indica a for√ßa do impacto da vari√°vel.

**Principais insights:**
- Vari√°veis como contrato mensal e maior cobran√ßa mensal aumentam a probabilidade de evas√£o.
- Tempo de contrato e maior quantidade de servi√ßos contratados reduzem significativamente o risco de churn.
- A Regress√£o Log√≠stica indica que a evas√£o est√° fortemente associada √† fideliza√ß√£o e ao custo percebido pelo cliente.

## SVM Linear ‚Äî Vari√°veis que Influenciam a Fronteira de Decis√£o

No SVM com kernel linear, os coeficientes indicam quais vari√°veis mais influenciam
a separa√ß√£o entre clientes evadidos e n√£o evadidos.
"""

from sklearn.svm import SVC

svm = SVC(kernel='linear', probability=True)
svm.fit(X_train_scaled, y_train)

coef_svm = pd.Series(
    svm.coef_[0],
    index=X.columns
).sort_values()

plt.figure(figsize=(8,10))
coef_svm.tail(10).plot(kind='barh', color='#c44e52')
coef_svm.head(10).plot(kind='barh', color='#4c72b0')
plt.title("Coeficientes do SVM Linear")
plt.tight_layout()
plt.show()

coef_svm.sort_values(key=abs, ascending=False).head(10)

"""**Principais insights:**
- Vari√°veis relacionadas ao custo e ao tempo de relacionamento
  influenciam diretamente a fronteira de decis√£o.
- O SVM confirma os padr√µes observados nos demais modelos.

"""

## KNN ‚Äî An√°lise Conceitual da Relev√¢ncia das Vari√°veis

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report

knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train_scaled, y_train)

y_pred_knn = knn.predict(X_test_scaled)

print(classification_report(y_test, y_pred_knn))

"""O KNN n√£o possui coeficientes expl√≠citos. A classifica√ß√£o √© baseada na dist√¢ncia entre clientes.
Assim, vari√°veis que mais influenciam a proximidade entre os pontos de dados s√£o as mais relevantes.
Por esse motivo, a padroniza√ß√£o dos dados √© essencial para esse modelo.

**Principais insights:**
- Vari√°veis cont√≠nuas como tempo de contrato, cobran√ßa mensal e custo di√°rio t√™m forte influ√™ncia,
  pois determinam a proximidade entre clientes.
- Clientes com perfis financeiros e tempo de perman√™ncia semelhantes tendem a apresentar
  comportamentos semelhantes de evas√£o.

## Conclus√£o da An√°lise de Relev√¢ncia das Vari√°veis

A an√°lise conjunta dos modelos indica que:
- O tempo de contrato √© o fator mais relevante para prever evas√£o.
- Contratos mensais e cobran√ßas mais altas aumentam o risco de churn.
- A contrata√ß√£o de m√∫ltiplos servi√ßos atua como fator de reten√ß√£o.
Esses padr√µes s√£o consistentes entre modelos lineares, baseados em dist√¢ncia e baseados em √°rvores,
refor√ßando a robustez das conclus√µes.

#üìç ETAPA EXTRA ‚Äî An√°lise de Desbalanceamento de Classes
"""

# =============================================================================
# AN√ÅLISE DE DESEQUIL√çBRIO DE CLASSES
# =============================================================================
print("\n‚öñÔ∏è An√°lise de Propor√ß√£o de Classes (Evas√£o)")

proporcao = df_final['Evasao'].value_counts(normalize=True)

print("Propor√ß√£o das classes:")
print(proporcao)

print(f"\nClientes Ativos (0): {proporcao[0]*100:.2f}%")
print(f"Clientes Evadidos (1): {proporcao[1]*100:.2f}%")

"""#‚öñÔ∏èBALANCEAMENTO COM SMOTE"""

# =============================================================================
# AN√ÅLISE DE DESEQUIL√çBRIO DE CLASSES
# =============================================================================
print("\n‚öñÔ∏è An√°lise de Propor√ß√£o de Classes (Evas√£o)")

proporcao = df_final['Evasao'].value_counts(normalize=True)

print("Propor√ß√£o das classes:")
print(proporcao)

print(f"\nClientes Ativos (0): {proporcao[0]*100:.2f}%")
print(f"Clientes Evadidos (1): {proporcao[1]*100:.2f}%")

# =============================================================================
# BALANCEAMENTO COM SMOTE
# =============================================================================

print("\nüß™ Pipeline com SMOTE (vers√£o corrigida e est√°vel)")

# -------------------------------------------------------------------------
# 1. Imports
# -------------------------------------------------------------------------
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, roc_auc_score
from imblearn.over_sampling import SMOTE
from collections import Counter

# -------------------------------------------------------------------------
# 2. Escalonamento (ANTES do SMOTE)
# -------------------------------------------------------------------------
scaler = StandardScaler()

X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled  = scaler.transform(X_test)

# -------------------------------------------------------------------------
# 3. Aplica√ß√£o do SMOTE (SOMENTE no treino)
# -------------------------------------------------------------------------
smote = SMOTE(random_state=42)

X_train_smote, y_train_smote = smote.fit_resample(
    X_train_scaled, y_train
)

print("\nDistribui√ß√£o das classes:")
print("Antes do SMOTE :", Counter(y_train))
print("Ap√≥s o SMOTE  :", Counter(y_train_smote))

# -------------------------------------------------------------------------
# 4. Treinamento do Modelo
# -------------------------------------------------------------------------
log_smote = LogisticRegression(
    max_iter=3000,
    solver='lbfgs',
    random_state=42
)

log_smote.fit(X_train_smote, y_train_smote)

# -------------------------------------------------------------------------
# 5. Avalia√ß√£o no conjunto de TESTE (N√ÉO balanceado)
# -------------------------------------------------------------------------
y_pred_smote = log_smote.predict(X_test_scaled)
y_proba_smote = log_smote.predict_proba(X_test_scaled)[:, 1]

print("\nüìä Avalia√ß√£o com SMOTE:")
print(classification_report(y_test, y_pred_smote))
print("ROC-AUC:", round(roc_auc_score(y_test, y_proba_smote), 4))